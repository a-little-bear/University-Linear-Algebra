# 第 62 章 矩阵补全

<div class="context-flow" markdown>

**前置**：奇异值分解 (Ch11) · 最优化基础 (Ch25) · 矩阵范数 (Ch15) · 概率论基础

**本章脉络**：矩阵补全的动机（Netflix 问题） $\to$ 低秩假设的核心地位 $\to$ 秩最小化问题的 NP-困难性 $\to$ 核范数 (Nuclear Norm) 凸松弛 $\to$ 可补全性条件：不相干性 (Incoherence) $\to$ 核心算法：奇异值阈值 (SVT)、交替最小二乘 (ALS) $\to$ Candes-Recht 定理（采样复杂度） $\to$ 应用：推荐系统、图像修复、传感器网络定位

**延伸**：矩阵补全是从局部观测推演全局真相的代数魔法；它利用高维空间中的“低秩结构”打破了采样定理的限制，证明了信息往往比数据本身更紧凑

</div>

假设你有一个巨大的矩阵，但其中 99% 的元素都是缺失的。你是否有办法把剩下的元素全部填对？这就是**矩阵补全**（Matrix Completion）的任务。在低秩（Low-rank）这一强大约束下，局部的信息足以通过算子结构的关联性“溢出”到全空间。本章将展示这一现代数据科学中的奇迹。

---

## 62.1 问题定义与低秩假设

!!! definition "定义 62.1 (矩阵补全问题)"
    给定矩阵 $M$ 在采样集 $\Omega$ 上的部分观测值 $M_{ij}, (i,j) \in \Omega$。寻找秩最小的矩阵 $X$ 使得 $X_{ij} = M_{ij}, \forall (i,j) \in \Omega$：
    $$\min \operatorname{rank}(X) \quad \text{subject to } P_\Omega(X) = P_\Omega(M)$$
    **挑战**：直接最小化秩是一个组合优化问题，被证明是 NP-困难的。

---

## 62.2 凸松弛与核范数

!!! technique "核范数松弛"
    为了使问题可解，我们将 $\operatorname{rank}(X)$ 替换为**核范数** $\|X\|_*$（奇异值之和）。
    $$\min \|X\|_* \quad \text{subject to } P_\Omega(X) = P_\Omega(M)$$
    这是一个凸优化问题，可以通过半正定规划 (SDP) 或专门的迭代算法高效求解。

---

## 62.3 何时可以补全？

!!! theorem "定理 62.1 (Candes-Recht 定理)"
    若 $n \times n$ 矩阵满足**不相干性条件**（即奇异向量不与坐标轴对齐），且随机采样的个数满足：
    $$m \ge C \cdot n r \log^2 n$$
    则通过核范数最小化，可以以极高概率精确恢复原矩阵。其中 $r$ 是矩阵的秩。

---

## 62.4 核心算法

!!! algorithm "算法 62.1 (奇异值阈值 SVT)"
    1.  初始化 $Y_0 = 0$。
    2.  计算 $X_k = \mathcal{D}_\tau(Y_k)$，其中 $\mathcal{D}_\tau$ 是奇异值收缩算符（保留 $\sigma_i > \tau$ 的部分并缩减）。
    3.  更新 $Y_{k+1} = Y_k + \delta P_\Omega(M - X_k)$。
    4.  重复直至收敛。

---

## 练习题

1. **[基础] 为什么不能补全一个只有一行非零的秩 1 矩阵？**

   ??? success "参考答案"
       因为这个矩阵高度“相干”（Incoherent 失败）。如果这一行中某个元素没被采样到，没有任何其他行可以提供关于它的信息。

2. **[核范数] 计算 $\operatorname{diag}(3, 4, 0)$ 的核范数。**

   ??? success "参考答案"
       奇异值为 3, 4, 0。核范数为 $3+4+0 = 7$。

3. **[采样] 对于 $1000 \times 1000$ 的秩 10 矩阵，理论上大约需要多少采样点？**

   ??? success "参考答案"
       根据 $n r \log n$，大约需要 $1000 \times 10 \times \ln(1000) \approx 7 \times 10^4$ 个采样点（约 7% 的数据）。

4. **[对比] NMF 与矩阵补全有什么联系？**

   ??? success "参考答案"
       NMF 也可以用于补全，它通过 $WH$ 的形式强制了低秩性，且额外施加了非负性约束，在推荐系统（如评分不为负）中非常常用。

5. **[性质] 证明：核范数是矩阵单位球（算子范数 $\le 1$）的对偶范数。**

   ??? success "参考答案"
       由 $\|A\|_* = \sup \{ \operatorname{tr}(A^T B) : \|B\|_2 \le 1 \}$ 得出。这是将向量 $L_1$ 范数对偶性推广到算子的结果。

6. **[SVT] 奇异值收缩算子 $\mathcal{D}_\tau$ 如何处理奇异值为 2 的项（若 $\tau=1$）？**

   ??? success "参考答案"
       将其变为 $2 - 1 = 1$。它类似于 $L_1$ 优化中的软阈值算子。

7. **[应用] 在 Netflix 问题中，缺失值代表什么？**

   ??? success "参考答案"
       代表用户尚未观看或尚未评分的电影。补全结果即为对用户兴趣的预测。

8. **[唯一性] 若采样点太少，补全结果唯一吗？**

   ??? success "参考答案"
       不唯一。存在无穷多个高秩矩阵满足观测值，低秩约束是挑选出唯一解的物理假设。

9. **[噪声] 在含噪声补全中，约束条件 $P_\Omega(X) = P_\Omega(M)$ 应如何修改？**

   ??? success "参考答案"
       松弛为不等式 $\|P_\Omega(X - M)\|_F \le \delta$。

10. **[极限] 秩最小化问题为什么不能直接用梯度下降？**

   ??? success "参考答案"
        因为秩函数是阶梯状的，其梯度在几乎所有地方都为 0，且在变化点处不连续，不具备引导下降的方向信息。

## 本章小结

矩阵补全是现代稀疏性理论的巅峰应用：

1.  **关联性的胜利**：它证明了在低秩背景下，数据并非孤立的条目，而是相互耦合的整体，局部观测足以通过算子的一致性约束推演全局。
2.  **凸性的桥梁**：核范数作为秩函数的“最佳凸逼近”，将不可解的组合难题转化为成熟的凸优化任务，实现了理论与算法的闭环。
3.  **信息的结构化**：不相干性条件的引入，为我们理解“什么是高质量数据”提供了代数判据，确立了随机采样在信息恢复中的核心价值。
