# 第 58 章 非负矩阵分解 (NMF)

<div class="context-flow" markdown>

**前置**：非负矩阵 (Ch17) · 矩阵分解 (Ch10) · SVD (Ch11) · 最优化 (Ch25)

**本章脉络**：NMF 的定义与“局部-整体”动机 $\to$ 与 PCA/SVD 的本质区别（可解释性） $\to$ NMF 的非凸性与 NP-困难性 $\to$ 几何意义：单纯形锥 $\to$ 核心算法：乘性更新规则 (Lee & Seung)、交替最小二乘 (ALS) $\to$ 正则化 NMF（稀疏性与流形约束） $\to$ 应用：图像特征提取、文本主题建模、生物信息学（基因表达聚类）

**延伸**：NMF 是数据挖掘中最重要的降维工具之一；它通过强制“非负性”约束，实现了对复杂数据的自动化特征解构，是让计算机理解“部分构成整体”逻辑的数学基础

</div>

在传统的矩阵分解（如 SVD）中，基向量和系数可以是负数，这在处理图像或文本时往往缺乏物理意义。**非负矩阵分解**（Non-negative Matrix Factorization, NMF）通过强制所有分量非负，使得分解结果具有自然的“局部构成整体”的可解释性。例如，人脸可以被自动分解为眼睛、鼻子等器官的组合。本章将探讨这一兼具非凸挑战与强大应用能力的分解技术。

---

## 58.1 定义与动机

!!! definition "定义 58.1 (NMF)"
    给定非负矩阵 $V \in \mathbb{R}^{m \times n}$，$V \ge 0$。NMF 寻找两个非负矩阵 $W \in \mathbb{R}^{m \times k}$ 和 $H \in \mathbb{R}^{k \times n}$ 使得：
    $$V \approx WH$$
    其中 $k \ll \min(m, n)$ 称为基的数量（秩）。

!!! intuition "可解释性：局部表示"
    由于不允许减法（负值），$V$ 的每一列只能由 $W$ 的列通过正向累加得到。这导致 $W$ 的列倾向于代表数据中的**基础局部特征**，而 $H$ 的行代表了这些特征的**激活强度**。

---

## 58.2 几何意义

!!! technique "几何：单纯形锥"
    NMF 的本质是寻找一个包含所有数据点 $V$ 的最小**非负单纯形锥**。数据的每一列被限制在由 $W$ 的列所张成的凸锥内。这与 PCA（寻找最大方差方向的线性空间）有着本质的几何差异。

---

## 58.3 核心算法

!!! algorithm "算法 58.1 (乘性更新规则)"
    由 Lee & Seung 提出的经典算法，通过以下迭代保证目标函数 $\|V-WH\|_F$ 非增：
    $$H_{aj} \leftarrow H_{aj} \frac{(W^T V)_{aj}}{(W^T WH)_{aj}}, \quad W_{ia} \leftarrow W_{ia} \frac{(VH^T)_{ia}}{(WHH^T)_{ia}}$$
    **优点**：实现极简单，自动保持非负性。
    **缺点**：收敛到局部极小值，可能陷入鞍点。

---

## 58.4 变体与扩展

!!! technique "变体：稀疏 NMF"
    通过在目标函数中加入 $L_1$ 正则项 $\lambda \|H\|_1$，可以强制基向量更加“纯粹”和稀疏，进一步增强特征的区分度。

---

## 练习题

1. **[基础] 证明：若 $V = WH$，则对任何正对角阵 $D$，$V = (WD)(D^{-1}H)$ 也是一个 NMF 分解。**
   ??? success "参考答案"
       $(WD)(D^{-1}H) = W(DD^{-1})H = WH = V$。由于 $D$ 及其逆元对角元为正，非负性保持。这说明 NMF 具有尺度缩放不唯一性。

2. **[对比] NMF 与 PCA 的主要区别是什么？**
   ??? success "参考答案"
       PCA 允许负值，追求方差最大化，特征往往是全局的；NMF 强制非负，追求可解释的局部构成。

3. **[NP-困难] 为什么 NMF 是 NP-困难的？**
   ??? success "参考答案"
       因为 NMF 本质上是一个非凸优化问题，且等价于寻找一个特定的单纯形嵌套，在一般维数下不存在多项式时间的最优解。

4. **[计算] 使用乘性更新规则，若某元素初始化为 0，它会改变吗？**
   ??? success "参考答案"
       不会。乘性更新中 0 乘以任何数仍为 0。因此，初始化对 NMF 的结果至关重要。

5. **[应用] 在文本主题建模中，$W$ 和 $H$ 分别代表什么？**
   ??? success "参考答案"
       $W$ 的每一列代表一个“主题”（关键词的分布）；$H$ 的每一列代表一篇文档对各个主题的“隶属度”。

6. **[秩] NMF 的秩 $k$ 是否等于矩阵的代数秩？**
   ??? success "参考答案"
       不一定。NMF 秩（非负秩）通常大于或等于代数秩。

7. **[测度] 除了 Frobenius 范数，NMF 还可以最小化什么距离？**
   ??? success "参考答案"
       常使用 **KL 散度**（Kullback-Leibler divergence），特别适用于计数数据和概率分布。

8. **[唯一性] 举出一个 NMF 分解不唯一的简单例子。**
   ??? success "参考答案"
       单位阵 $I$ 的分解 $I = I \cdot I$。由于尺度缩放和旋转（保持非负性时）的存在，分解通常不唯一。

9. **[初始化] 为什么不能用全 0 初始化 NMF？**
   ??? success "参考答案"
       全 0 是梯度的稳定平衡点，迭代将永远停留在那，且无法提取任何特征。通常使用随机正值或基于 SVD 的 NNDSVD 初始化。

10. **[性质] 证明若 $V$ 的某一行为全 0，则 $W$ 的对应行也必为全 0。**
    ??? success "参考答案"
        因为 $V_{ij} = \sum W_{ik} H_{kj}$。若左边为 0 且右边项均非负，则每一项必为 0。若 $H$ 有意义，则 $W_{ik}$ 必为 0。

## 本章小结

NMF 实现了线性代数与认知的和谐：

1.  **非负性的哲学**：它证明了数学约束（非负性）不仅是限制，更是产生“意义”（局部特征）的源泉，确立了降维算法的可解释性基准。
2.  **非凸的挑战**：NMF 展示了即使是最简单的线性乘积，在带有符号约束时也会演化为复杂的非凸景观，推动了交替优化算法的发展。
3.  **模式的解构**：从图像识别到基因组学，NMF 作为一种通用的“模式发现”工具，证明了复杂的现实数据往往是由少数纯粹的、非负的原子成分叠加而成的。
