# 第 06 章 特征值与特征向量

<div class="context-flow" markdown>

**前置**：行列式 (Ch03) · 线性变换 (Ch05)

**本章脉络**：特征值与特征向量定义 $\to$ 特征方程与特征多项式 $\to$ 代数重数与几何重数 $\to$ 相似变换 $\to$ 矩阵可对角化的判定定理 $\to$ 特殊矩阵的谱（对称阵、三角阵） $\to$ Cayley-Hamilton 定理 $\to$ 矩阵幂的计算 $\to$ 谱半径与稳定性初步

**延伸**：特征值分析是理解动力系统稳定性、Google PageRank 算法及量子力学能级的关键；它是 Jordan 标准形 (Ch12) 的基础

</div>

特征值和特征向量揭示了线性变换最本质的“不变方向”。一个复杂的矩阵作用在特定向量上，可能仅仅表现为一种缩放。寻找这些缩放因子及其对应的方向，是简化矩阵运算、分析系统长期行为的核心手段。

---

## 06.1 定义与特征方程

!!! definition "定义 06.1 (特征值与特征向量)"
    设 $A$ 是 $n$ 阶方阵。若存在非零向量 $\mathbf{v}$ 和标量 $\lambda$，使得：
    $$A\mathbf{v} = \lambda\mathbf{v}$$
    则称 $\lambda$ 为 $A$ 的**特征值**（Eigenvalue），$\mathbf{v}$ 为对应于 $\lambda$ 的**特征向量**（Eigenvector）。

!!! definition "定义 06.2 (特征多项式)"
    方程 $\det(A - \lambda I) = 0$ 称为 $A$ 的**特征方程**。其左侧 $p(\lambda) = \det(A - \lambda I)$ 是关于 $\lambda$ 的 $n$ 次多项式，称为**特征多项式**。

---

## 06.2 重数与特征空间

!!! definition "定义 06.3 (代数重数与几何重数)"
    1.  **代数重数**：特征值 $\lambda_i$ 作为特征方程根的重数。
    2.  **几何重数**：特征空间 $E_{\lambda_i} = \ker(A - \lambda_i I)$ 的维数，即线性无关特征向量的最大个数。
    **性质**：几何重数 $\leq$ 代数重数。

---

## 06.3 对角化

!!! theorem "定理 06.1 (可对角化判定)"
    $n$ 阶方阵 $A$ 可对角化 $\iff$ $A$ 有 $n$ 个线性无关的特征向量 $\iff$ 每个特征值的几何重数等于代数重数。
    对角化形式为：$P^{-1}AP = \Lambda = \operatorname{diag}(\lambda_1, \ldots, \lambda_n)$。

---

## 06.4 Cayley-Hamilton 定理

!!! theorem "定理 06.2 (Cayley-Hamilton 定理)"
    每一个方阵都满足其自身的特征方程。即若 $p(\lambda) = \det(A - \lambda I)$，则 $p(A) = O$。
    **应用**：该定理可用于高效计算矩阵的高次幂以及逆矩阵 $A^{-1}$。

---

## 练习题

**1. [计算] 求 $A = \begin{pmatrix} 4 & -5 \\ 2 & -3 \end{pmatrix}$ 的特征值。**

??? success "参考答案"
    **解特征方程：**
    1. 写出 $\det(A - \lambda I) = \begin{vmatrix} 4-\lambda & -5 \\ 2 & -3-\lambda \end{vmatrix}$。
    2. 展开行列式：$(4-\lambda)(-3-\lambda) - (-10) = \lambda^2 - \lambda - 12 + 10 = \lambda^2 - \lambda - 2 = 0$。
    3. 因式分解：$(\lambda - 2)(\lambda + 1) = 0$。
    **结论**：特征值为 $\lambda_1 = 2, \lambda_2 = -1$。

**2. [特征向量] 求上题中 $\lambda = 2$ 对应的特征向量。**

??? success "参考答案"
    **解线性方程组 $(A - 2I)\mathbf{v} = 0$：**
    1. 计算 $A - 2I = \begin{pmatrix} 4-2 & -5 \\ 2 & -3-2 \end{pmatrix} = \begin{pmatrix} 2 & -5 \\ 2 & -5 \end{pmatrix}$。
    2. 方程组为 $2v_1 - 5v_2 = 0$。
    3. 取自由变量 $v_2 = 2$，则 $v_1 = 5$。
    **结论**：特征向量为 $\mathbf{v} = k \begin{pmatrix} 5 \\ 2 \end{pmatrix}, k \neq 0$。

**3. [对角化] 若 $A$ 的特征值各不相同，它是否一定可对角化？**

??? success "参考答案"
    **结论：**
    是的。这是一个重要判定：**具有 $n$ 个互异特征值的 $n$ 阶矩阵必然可对角化**。
    **理由**：不同特征值对应的特征向量必然线性无关。既然有 $n$ 个互异特征值，我们就拥有了 $n$ 个线性无关特征向量，构成了空间的一组基。

**4. [性质] 证明：若 $A$ 可逆，则其特征值均不为 0。**

??? success "参考答案"
    **证明：**
    1. 设 $\lambda$ 是 $A$ 的一个特征值，则 $A\mathbf{v} = \lambda\mathbf{v}$。
    2. 若 $\lambda = 0$，则 $A\mathbf{v} = \mathbf{0}$ 对非零向量 $\mathbf{v}$ 成立。
    3. 这意味着 $A$ 的核不为零，即 $A$ 是奇异矩阵（不可逆）。
    4. 矛盾。因此可逆矩阵的所有特征值必非零。

**5. [迹与行列式] 矩阵的迹与特征值之和有什么关系？**

??? success "参考答案"
    **定理：**
    1. **迹的关系**：$\operatorname{tr}(A) = \sum_{i=1}^n \lambda_i$（特征值之和等于主对角线元素之和）。
    2. **行列式关系**：$\det(A) = \prod_{i=1}^n \lambda_i$（特征值之积等于行列式）。
    这是通过对比特征多项式展开式的系数直接得出的。

**6. [三角阵] 上三角矩阵的特征值是什么？**

??? success "参考答案"
    **结论：**
    上三角（或下三角、对角）矩阵的特征值就是其**主对角线上的所有元素**。
    **理由**：因为 $(A - \lambda I)$ 仍是三角阵，其行列式直接等于对角线元素的乘积 $\prod (a_{ii} - \lambda)$。

**7. [相似] 证明相似矩阵具有相同的特征多项式。**

??? success "参考答案"
    **证明：**
    1. 设 $B = P^{-1}AP$。
    2. $\det(B - \lambda I) = \det(P^{-1}AP - \lambda P^{-1}IP) = \det(P^{-1}(A - \lambda I)P)$。
    3. 利用行列式乘法性质：$= \det(P^{-1})\det(A - \lambda I)\det(P)$。
    4. 由于 $\det(P^{-1})\det(P) = 1$，结果为 $\det(A - \lambda I)$。
    **结论**：特征多项式是相似变换下的不变量。

**8. [幂运算] 若 $A = PDP^{-1}$，计算 $A^{10}$。**

??? success "参考答案"
    **推导过程：**
    1. $A^2 = (PDP^{-1})(PDP^{-1}) = PD(P^{-1}P)DP^{-1} = PD^2P^{-1}$。
    2. 重复上述过程 $k$ 次：$A^k = PD^kP^{-1}$。
    3. 对于对角阵 $D$， $D^{10}$ 仅需将对角元分别取 10 次方。
    **结论**：利用对角化可极大简化大矩阵的高次幂运算。

**9. [C-H定理] 已知 $A^2 - 3A + 2I = O$，若 $A$ 可逆，求 $A^{-1}$。**

??? success "参考答案"
    **步骤：**
    1. 将 $I$ 孤立出来：$2I = 3A - A^2$。
    2. 两边左乘 $A^{-1}$：$2A^{-1} = 3I - A$。
    3. 解出逆矩阵：$A^{-1} = \frac{1}{2}(3I - A)$。
    这种方法在不知道矩阵具体元素、仅知道其零化多项式时非常有效。

**10. [重数] 举例说明几何重数小于代数重数的情况。**
    
??? success "参考答案"
    **典型例子：Jordan块**
    $A = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$。
    1. **特征方程**：$\lambda^2 = 0 \implies \lambda = 0$（代数重数为 2）。
    2. **求特征向量**：$A\mathbf{v} = 0 \implies \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = 0 \implies v_2 = 0$。
    3. 所有的特征向量都具有形式 $(k, 0)^T$，即特征空间是一维的（几何重数为 1）。
    **结论**：这种特征向量缺失的矩阵称为**亏损矩阵**（Defective Matrix），不可对角化。
