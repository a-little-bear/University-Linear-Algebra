# 第 21 章 多线性代数与张量

<div class="context-flow" markdown>

**前置**：Kronecker 积(Ch19) · 向量空间(Ch4) · 对偶空间(Ch13a)

**本章脉络**：多线性映射定义 → 张量积 $V \otimes W$ → 张量的秩与分解（CP 分解、Tucker 分解） → 模-$n$ 乘积 → 张量收缩 → 算术张量（对称与反对称张量） → 应用（高维数据压缩、量子纠缠、化学计量学）

**延伸**：张量是矩阵的自然高阶推广；多线性代数将二元关系的矩阵论推向了多元关系的复杂领域

</div>

多线性代数研究多个向量空间之间的线性相互作用。张量不仅仅是多维数组，它是多线性映射的代数表示。在深度学习和量子计算时代，张量分解已成为处理“维度灾难”的核心技术。

---

## 21.1 张量积与分解

!!! definition "定义 21.1 (张量积空间)"
    向量空间 $V$ 和 $W$ 的张量积 $V \otimes W$ 是满足通用性质的向量空间，使得任何双线性映射 $B: V 	imes W 	o U$ 都可以唯一分解为线性映射 $	ilde{B}: V \otimes W 	o U$。

!!! theorem "定理 21.3 (CP 分解)"
    任何三阶张量 $\mathcal{X} \in \mathbb{R}^{I 	imes J 	imes K}$ 都可以分解为有限个秩-1 张量的和：
    $$\mathcal{X} = \sum_{r=1}^R a_r \circ b_r \circ c_r$$
    其中最小的 $R$ 称为张量的 **CP 秩**。

---

## 练习题

1. **[维数] 若 $\dim V = 3, \dim W = 4$，求 $\dim(V \otimes W)$。**
   ??? success "参考答案"
       $\dim(V \otimes W) = \dim V \cdot \dim W = 3 \cdot 4 = 12$。

2. **[张量秩] 举出一个二阶张量（矩阵）秩为 1 的例子。**
   ??? success "参考答案"
       外积 $v \circ w = v w^T$。例如 $\begin{pmatrix} 1 \ 2 \end{pmatrix} \begin{pmatrix} 3 & 4 \end{pmatrix} = \begin{pmatrix} 3 & 4 \ 6 & 8 \end{pmatrix}$。其秩为 1。

3. **[模-n乘积] 描述张量 $\mathcal{X}$ 与矩阵 $M$ 的模-1 乘积 $\mathcal{X} 	imes_1 M$ 的含义。**
   ??? success "参考答案"
       它表示沿着张量的第一个维度（行方向）应用线性变换 $M$。如果将张量看作一组矩阵页，则每一页的列向量都被 $M$ 变换。

4. **[计算] 若 $\mathcal{X} = a \circ b \circ c$，求其向量化形式 $\operatorname{vec}(\mathcal{X})$。**
   ??? success "参考答案"
       $\operatorname{vec}(\mathcal{X}) = c \otimes b \otimes a$（按照通常的字典序约定）。

5. **[Tucker分解] Tucker 分解的核心张量 (Core Tensor) 起什么作用？**
   ??? success "参考答案"
       核心张量捕捉了不同维度基向量之间的相互作用。它类似于 SVD 中的奇异值矩阵，但允许非对角项，从而能描述更复杂的跨维度关联。

6. **[张量收缩] 解释两个二阶张量（矩阵） $A, B$ 的完全收缩。**
   ??? success "参考答案"
       这对应于 Frobenius 内积 $\langle A, B angle = \sum A_{ij} B_{ij} = \operatorname{tr}(A^T B)$。收缩操作通过对相同指标求和来降低张量的阶数。

7. **[对称张量] 举出一个三阶对称张量的例子。**
   ??? success "参考答案"
       多元随机变量的三阶矩 $\mathbb{E}[X \otimes X \otimes X]$ 是对称的，因为 $\mathbb{E}[X_i X_j X_k]$ 的值与指标 $i, j, k$ 的排列无关。

8. **[秩的差异] 为什么张量的 CP 秩比矩阵的秩更难计算？**
   ??? success "参考答案"
       矩阵秩可以通过 SVD 在多项式时间内精确求得。张量 CP 秩的确定是 NP-困难的，且张量秩可能在实数域和复数域上不同，甚至可能出现“秩不闭合”的现象。

9. **[应用] 在高光谱图像处理中，为什么用张量模型比矩阵模型好？**
    ??? success "参考答案"
        图像具有空间（2维）和光谱（1维）三个维度。矩阵模型需要强行平铺（Vectorization），破坏了空间局部性。张量模型能够直接保持空间-光谱的结构特征，从而实现更有效的信息提取和降噪。

10. **[反对称张量] 证明在 3 维空间中，三阶完全反对称张量的维数是 1。**
    ??? success "参考答案"
        反对称张量对应于外代数 $\Lambda^3(\mathbb{R}^3)$。其维数为 $\binom{3}{3} = 1$。其基元素即为 Levi-Civita 符号 $\epsilon_{ijk}$。

## 本章小结

多线性代数扩展了线性思维的边界：

1. **维度跃迁**：从线性的“线”与“面”转向了相互嵌套的“体”结构。
2. **结构分解**：CP 和 Tucker 分解为挖掘高维数据的隐藏关联提供了代数蓝图。
3. **几何刚性**：张量秩的独特性（如 CP 分解在弱条件下是唯一的）使其在盲源分离等领域具有矩阵不可比拟的优势。
