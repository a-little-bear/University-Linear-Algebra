# 第 72B 章 多元统计推断

<div class="context-flow" markdown>

**前置**：矩阵微积分(Ch47) · Wishart 分布(Ch72A) · QR 分解(Ch10) · SVD (Ch11)

**本章脉络**：参数估计 (MLE) → Hotelling’s $T^2$ 检验 → 多元方差分析 (MANOVA) → 典型相关分析 (CCA) → 结构方程模型 (SEM) → 高维协方差阵估计 → 收缩估计量 (Ledoit-Wolf)

**延伸**：多元统计推断将随机矩阵的谱理论应用于不确定性下的决策；CCA 是寻找两组多维变量间相关性的代数桥梁

</div>

多元统计推断利用矩阵代数对高维数据进行假设检验和参数估计。该领域将群体差异的比较转化为矩阵谱（特征值）的比较，将变量间的依赖关系转化为子空间夹角的几何问题。

---

## 72B.1 核心估计量与检验理论

!!! definition "定义 72B.1 (均值与协方差的 MLE)"
    对于 $\mathcal{N}_p(\mu, \Sigma)$，在给定 $n$ 个样本后，其极大似然估计量为：
    $$\hat{\mu} = \bar{x}, \quad \hat{\Sigma} = \frac{1}{n} \sum (x_i - \bar{x})(x_i - \bar{x})^T$$
    它们是样本点云在参数空间上的正交投影。

!!! theorem "定理 72B.3 (Wilks' Lambda 与 MANOVA)"
    在多元方差分析中，比较组间均值的检验统计量为 Wilks' Lambda：
    $$\Lambda = \frac{\det(E)}{\det(E + H)}$$
    其中 $E$ 为误差（组内）平方和矩阵，$H$ 为假设（组间）平方和矩阵。该统计量是 $E^{-1}H$ 特征值的函数。

---

## 练习题

1. **[群体比较] 为什么多元方差分析 (MANOVA) 使用矩阵行列式而不是简单的方差求和？**
   ??? success "参考答案"
       行列式 $\det(E)$ 代表了样本簇的“广义方差”或体积。MANOVA 考虑了变量间的相关性；若仅对方差求和，会忽略协方差结构，在变量非正交时导致错误的推断结论。

2. **[Hotelling's T-squared] 证明 Hotelling’s $T^2$ 是单变量 t-统计量平方的多元推广。**
   ??? success "参考答案"
       $T^2 = n(\bar{x}-\mu)^T S^{-1}(\bar{x}-\mu)$。在标量情形（$p=1$）下，这缩减为 $n(\bar{x}-\mu)^2 / s^2 = t^2$。利用矩阵逆 $S^{-1}$（马氏距离）实现了在所有相关维度上的距离标准化。

3. **[CCA几何] 在典型相关分析 (CCA) 中，典型相关系数如何与两个子空间的夹角联系？**
   ??? success "参考答案"
       典型相关系数是变量集 $X$ 张成的子空间与变量集 $Y$ 张成的子空间之间**主角**（Principal Angles）的余弦值。最大化相关性等价于在各子空间中寻找角度最接近的向量。

4. **[计算] 给定误差阵 $E = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}$ 和假设阵 $H = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}$。计算 Wilks' $\Lambda$。**
   ??? success "参考答案"
       计算 $E+H = \begin{pmatrix} 3 & 1 \\ 1 & 2 \end{pmatrix}$。
       $\det(E) = 4-1 = 3$；$\det(E+H) = 6-1 = 5$。
       故 $\Lambda = 3/5 = 0.6$。较小的 $\Lambda$ 表明有更强的证据拒绝原假设。

5. **[判别分析] 将 Fisher 线性判别分析与广义特征值问题联系起来。**
   ??? success "参考答案"
       Fisher 寻找一个投影向量 $w$ 以最大化 $J(w) = \frac{w^T H w}{w^T E w}$。对 $w$ 求导导致广义特征值方程 $Hw = \lambda Ew$。最优投影方向即为 $E^{-1}H$ 最大特征值对应的特征向量。

6. **[收缩估计] 为什么在高维情形（$p \approx n$）下，MLE 估计量 $\hat{\Sigma}$ 会出现病态？**
   ??? success "参考答案"
       随着 $p/n$ 增大，样本特征值会变得异常分散（Marchenko-Pastur 规律）。最小特征值偏向于零，导致 $S^{-1}$ 不稳定。Ledoit-Wolf 收缩估计通过凸组合 $S(\lambda) = (1-\lambda)S + \lambda I$ 将特征值向均值拉拢，提高数值稳定性。

7. **[SVD与回归] 描述 SVD 在主成分回归 (PCR) 中的作用。**
   ??? success "参考答案"
       PCR 首先对设计矩阵 $X = U\Sigma V^T$ 进行 SVD，然后将响应变量 $y$ 对 $U$ 的前 $k$ 列进行回归。这通过利用正交的主成分作为预测因子，消除了原始变量间的共线性问题。

8. **[不变性] Hotelling’s $T^2$ 统计量在非奇异线性变换 $x \mapsto Ax + b$ 下是否保持不变？**
   ??? success "参考答案"
       是的。将变换后的均值和协方差代入 $T^2$ 公式，矩阵 $A$ 与 $A^{-1}$ 会抵消，证明检验结果独立于坐标系的选取。

9. **[偏相关] 解释精度矩阵 $\Omega = \Sigma^{-1}$ 与偏相关系数的关系。**
   ??? success "参考答案"
       协方差阵逆矩阵的 $(i,j)$ 元在归一化后等于在给定其他所有变量条件下，变量 $i$ 与 $j$ 之间偏相关系数的相反数。$\Omega$ 中的零元素对应条件独立性（高斯图形模型）。

10. **[谱假设] 最大特征值 $\lambda_{\max}(E^{-1}H)$ 的分布与 Roy 最大根检验有何联系？**
    ??? success "参考答案"
        Roy 检验仅使用最大特征值作为统计量。当组间差异集中在单一维度上（秩-1 备择假设）时，该检验效能最高，反映了谱半径对结构化扰动的敏感性。

## 本章小结

本章将矩阵理论应用于统计决策逻辑：

1. **谱比较**：确立了群体差异检验作为相对矩阵谱 ($E^{-1}H$) 的分析过程。
2. **子空间对齐**：形式化了 CCA 作为通过 SVD 最小化变量子空间夹角的问题。
3. **正则化估计**：引入收缩方法解决了高维环境下样本矩阵的数值不稳定性。
4. **距离几何**：利用马氏度量和二次型定义了稳健的多元假设检验。
